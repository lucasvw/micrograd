{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d553b43",
   "metadata": {},
   "source": [
    "Discussion on discord:\n",
    "\n",
    "_Did anyone else find that indexing into the weight matrix was slower than using the \"redundant\" one-hot encoded vectors? The perf difference was around 8x for me on GPU.\n",
    "I'm guessing it's faster to let the GPU rip through the matmul than have to do many random memory lookups._\n",
    "\n",
    "https://discord.com/channels/1020383067459821711/1029849849765564528/1056756317777305710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a37e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69652fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_dimensions = 703 # Trigram word model input: (.., .a, [...], .z, aa, [...], az)\n",
    "col_dimensions = 27 # Trigram word model output: (., a, [...], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db288660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated weight matrix\n",
    "W = torch.randn([row_dimensions, col_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d4e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated X matrix, consisting of 1000 random integers between 0 and 703\n",
    "X = torch.randint(low=0, high = row_dimensions, size=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b257035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoded x_enc matrix\n",
    "x_enc = F.one_hot(X, num_classes=row_dimensions).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca6fcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative1: using matrix multiplication between one-hot encoded matrix and W\n",
    "a1 = x_enc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea0180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative2: directly indexing into W with original X vector\n",
    "a2 = W[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c476ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the results are the same\n",
    "assert torch.allclose(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb284ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416 µs ± 3.94 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x_enc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f001c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.3 µs ± 156 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "W[X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919a466",
   "metadata": {},
   "source": [
    "### Directly indexing into W is roughly 10 times faster then using matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80aa3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35 ms ± 132 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x_enc = F.one_hot(X, num_classes=row_dimensions).float()\n",
    "x_enc @ W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f1f3d",
   "metadata": {},
   "source": [
    "### If we also consider the duration of creating the one_hot encoded matrix, the difference is even larger, it's 1300 vs 35 $\\mu$s, a factor 40!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc047b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
