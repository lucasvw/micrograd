{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasvanwalstijn/miniconda3/envs/fastai/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.txt') as file:\n",
    "    names = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = set()\n",
    "for name in names:\n",
    "    for letter in name:\n",
    "        letters.add(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list(sorted(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First idea is to do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "emma\n",
      ".e -> m\n",
      "em -> m\n",
      "mm -> a\n",
      "ma -> .\n",
      "########\n",
      "########\n",
      "olivia\n",
      ".o -> l\n",
      "ol -> i\n",
      "li -> v\n",
      "iv -> i\n",
      "vi -> a\n",
      "ia -> .\n",
      "########\n",
      "########\n",
      "ava\n",
      ".a -> v\n",
      "av -> a\n",
      "va -> .\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "for name in names[:3]:\n",
    "    print('########')\n",
    "    print(name)\n",
    "    name = '.' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        print(i+j, '->',k)\n",
    "    print('########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do this, then we have the problem that the very first 3-gram is actually not starting from a neutral state, it starts with \".x\" where x is the first letter of the name. So instead, we need to do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "emma\n",
      ".. -> e\n",
      ".e -> m\n",
      "em -> m\n",
      "mm -> a\n",
      "ma -> .\n",
      "########\n",
      "########\n",
      "olivia\n",
      ".. -> o\n",
      ".o -> l\n",
      "ol -> i\n",
      "li -> v\n",
      "iv -> i\n",
      "vi -> a\n",
      "ia -> .\n",
      "########\n",
      "########\n",
      "ava\n",
      ".. -> a\n",
      ".a -> v\n",
      "av -> a\n",
      "va -> .\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "for name in names[:3]:\n",
    "    print('########')\n",
    "    print(name)\n",
    "    name = '..' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        print(i+j, '->',k)\n",
    "    print('########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to append `..` to the beginning, then we start with a neutral state and predict the first letter from that neutral state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to construct the matrix in which we will store the counts. Previously we had a 27x27 matrix to store all this information, but now that we have a trigram, so the row dimension will become larger. Because the row dimension will have to cover all the `..`, `.x` and `xy` combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With itertools product we can make these kind of combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "list(product([1,2,3], [1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['..',\n",
       "  ('.', 'a'),\n",
       "  ('.', 'b'),\n",
       "  ('.', 'c'),\n",
       "  ('.', 'd'),\n",
       "  ('.', 'e'),\n",
       "  ('.', 'f'),\n",
       "  ('.', 'g'),\n",
       "  ('.', 'h'),\n",
       "  ('.', 'i')],\n",
       " [('z', 'q'),\n",
       "  ('z', 'r'),\n",
       "  ('z', 's'),\n",
       "  ('z', 't'),\n",
       "  ('z', 'u'),\n",
       "  ('z', 'v'),\n",
       "  ('z', 'w'),\n",
       "  ('z', 'x'),\n",
       "  ('z', 'y'),\n",
       "  ('z', 'z')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = ['..'] + list(product('.', letters)) + list(product(letters, letters))\n",
    "combinations[0:10], combinations[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_to_i = {c[0]+c[1]:i for i, c in enumerate(combinations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss_to_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_to_i = {s: i+1 for i,s in enumerate(letters)}\n",
    "s_to_i['.'] = 0\n",
    "\n",
    "i_to_s = {i: s for s,i in s_to_i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_to_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple counting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. -> e\n",
      ".e -> m\n",
      "em -> m\n",
      "mm -> a\n",
      "ma -> .\n",
      ".. -> o\n",
      ".o -> l\n",
      "ol -> i\n",
      "li -> v\n",
      "iv -> i\n",
      "vi -> a\n",
      "ia -> .\n",
      ".. -> a\n",
      ".a -> v\n",
      "av -> a\n",
      "va -> .\n",
      "tensor(228146.) torch.Size([703, 27])\n"
     ]
    }
   ],
   "source": [
    "combinations = ['..'] + list(product('.', letters)) + list(product(letters, letters))\n",
    "\n",
    "ss_to_i = {c[0]+c[1]:i for i, c in enumerate(combinations)}\n",
    "\n",
    "for name in names[:3]:\n",
    "    name = '..' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        print(i+j, '->',k)\n",
    "\n",
    "N = torch.zeros((len(ss_to_i), len(s_to_i)))\n",
    "\n",
    "for name in names:\n",
    "    name = '..' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        row = ss_to_i[i+j]\n",
    "        col = s_to_i[k]\n",
    "        N[row, col] += 1\n",
    "print(N.sum(), N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..mip\n",
      "..axx\n",
      "..mereyannyaar\n",
      "..knooraen\n",
      "..el\n",
      "..marviovania\n",
      "..odarimalaalexiaganilley\n",
      "..helahroni\n",
      "..haat\n",
      "..affiya\n",
      "..isemarrisleemikh\n",
      "..bech\n",
      "..amilleia\n",
      "..trutandenneppalycethon\n",
      "..jan\n",
      "..kryn\n",
      "..yusehanii\n",
      "..laymira\n",
      "..knoenoah\n",
      "..nowynni\n"
     ]
    }
   ],
   "source": [
    "# Smoothing\n",
    "# N = N+1\n",
    "\n",
    "# Use this model to generate some names:\n",
    "\n",
    "P = N / N.sum(1, keepdim=True)\n",
    "\n",
    "assert P[0].sum().item() - 1.0 < 1e-5\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = \"..\"\n",
    "    while True:\n",
    "        ss = name[-2:]\n",
    "        i = ss_to_i[ss]\n",
    "        sampled_i = int(torch.multinomial(P[i], 1, replacement=True, generator=g).item())\n",
    "        sampled_s = i_to_s[sampled_i]\n",
    "        if sampled_i == 0:\n",
    "            break\n",
    "        name += sampled_s\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll.item()=2.0619611740112305\n"
     ]
    }
   ],
   "source": [
    "# What's the negative loss likelihood of our model? Depends on how we do this, here we use \".name.\", which is wrong:\n",
    "\n",
    "sumlogprob = torch.tensor(0.0)\n",
    "count = 0\n",
    "for name in names:\n",
    "    name = '.' + name + '.'\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        prob = P[ss_to_i[ch1+ch2], s_to_i[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        sumlogprob += logprob\n",
    "        count += 1\n",
    "nll = -sumlogprob / count\n",
    "print(f'{nll.item()=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll.item()=2.185652017593384\n"
     ]
    }
   ],
   "source": [
    "# What's the negative loss likelihood of our model? Depends on how we do this, here we use \"..name.\":\n",
    "\n",
    "sumlogprob = torch.tensor(0.0)\n",
    "count = 0\n",
    "for name in names:\n",
    "    name = '..' + name + '.'\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        prob = P[ss_to_i[ch1+ch2], s_to_i[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        sumlogprob += logprob\n",
    "        count += 1\n",
    "nll = -sumlogprob / count\n",
    "print(f'{nll.item()=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of the 2D matrix that holds the counts, we can also use a 3D tensor of size 27x27x27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(228146.) torch.Size([27, 27, 27])\n"
     ]
    }
   ],
   "source": [
    "N = torch.zeros((len(s_to_i), len(s_to_i), len(s_to_i)))\n",
    "\n",
    "for name in names:\n",
    "    name = '..' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        ix1 = s_to_i[i]\n",
    "        ix2 = s_to_i[j]\n",
    "        ix3 = s_to_i[k]\n",
    "        N[ix1, ix2, ix3] += 1\n",
    "print(N.sum(), N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..mip\n",
      "..axx\n",
      "..mereyannyaar\n",
      "..knooraen\n",
      "..el\n",
      "..marviovania\n",
      "..odarimalaalexiaganilley\n",
      "..helahroni\n",
      "..haat\n",
      "..affiya\n",
      "..isemarrisleemikh\n",
      "..bech\n",
      "..amilleia\n",
      "..trutandenneppalycethon\n",
      "..jan\n",
      "..kryn\n",
      "..yusehanii\n",
      "..laymira\n",
      "..knoenoah\n",
      "..nowynni\n"
     ]
    }
   ],
   "source": [
    "# Smoothing\n",
    "# N = N+100\n",
    "\n",
    "# Use this model to generate some names:\n",
    "\n",
    "P = N / N.sum(2, keepdim=True)\n",
    "\n",
    "assert P[0,0].sum().item() - 1.0 < 1e-5\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = \"..\"\n",
    "    while True:\n",
    "        ix1 = s_to_i[name[-2]]\n",
    "        ix2 = s_to_i[name[-1]]\n",
    "        sampled_i = int(torch.multinomial(P[ix1, ix2], 1, replacement=True, generator=g).item())\n",
    "        sampled_s = i_to_s[sampled_i]\n",
    "        if sampled_i == 0:\n",
    "            break\n",
    "        name += sampled_s\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll.item()=2.185652017593384\n"
     ]
    }
   ],
   "source": [
    "# What's the negative loss likelihood of our model?\n",
    "sumlogprob = torch.tensor(0.0)\n",
    "count = 0\n",
    "for name in names:\n",
    "    name = '..' + name + '.'\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        ix1 = s_to_i[ch1]\n",
    "        ix2 = s_to_i[ch2]\n",
    "        ix3 = s_to_i[ch3]\n",
    "        prob = P[ix1, ix2, ix3]\n",
    "        logprob = torch.log(prob)\n",
    "        sumlogprob += logprob\n",
    "        count += 1\n",
    "nll = -sumlogprob / count\n",
    "print(f'{nll.item()=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows the exact same number as before, that's nice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to make the same model but then with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets:\n",
    "\n",
    "xs = []\n",
    "x1s = []\n",
    "x2s = []\n",
    "ys = []\n",
    "\n",
    "for name in names:\n",
    "    name = '..' + name + '.'\n",
    "    for x1, x2, y in zip(name, name[1:], name[2:]):\n",
    "        x1s.append(s_to_i[x1])\n",
    "        x2s.append(s_to_i[x2])\n",
    "        xs.append([s_to_i[x1], s_to_i[x2]])\n",
    "        ys.append(s_to_i[y])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "x1s = torch.tensor(x1s)\n",
    "x2s = torch.tensor(x2s)\n",
    "ys = torch.tensor(ys)\n",
    "num = len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 5]), tensor([ 0,  5, 13]))"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1s[:3], x2s[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0],\n",
       "        [ 0,  5],\n",
       "        [ 5, 13]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.arange(3*3*3).reshape([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26]]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.nn.functional.one_hot(torch.tensor(0), num_classes=3)\n",
    "x2 = torch.nn.functional.one_hot(torch.tensor(1), num_classes=3)\n",
    "xs = torch.nn.functional.one_hot(torch.tensor([0,1]), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10, 11])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 @ (x1 @ W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 9, 10, 11],\n",
       "        [18, 19, 20]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1 @ W).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2 @ (x1 @ W)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.nn.functional.one_hot(torch.tensor([0,0]), num_classes=3)\n",
    "x2 = torch.nn.functional.one_hot(torch.tensor([1,1]), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (9x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [343]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (9x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "x2 @ (x1 @ W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 3])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1 @ W).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 0,  1,  2]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [18, 19, 20]]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1 @ W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (6x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [348]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "x2.view(3,-1) @ (x1 @ W).view(3,3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.view(3,-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This really doesn't work, I don't know how we can use two one-hot encoded vectors and multiply that with W to get the row vector we are interested in, instead we can just index into W:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 5]), tensor([ 0,  5, 13]))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1s[:3], x2s[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.rand((27,27,27), dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.340085506439209\n",
      "3.1340880393981934\n",
      "3.0591394901275635\n",
      "2.8926663398742676\n",
      "2.837334156036377\n",
      "2.8620455265045166\n",
      "2.7483880519866943\n",
      "2.697908878326416\n",
      "2.733649730682373\n",
      "2.6369221210479736\n",
      "2.6320204734802246\n",
      "2.6898727416992188\n",
      "2.5979843139648438\n",
      "2.558075428009033\n",
      "2.5886223316192627\n",
      "2.524501323699951\n",
      "2.5174810886383057\n",
      "2.5000827312469482\n",
      "2.503399610519409\n",
      "2.508382797241211\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    logits = W[x1s, x2s, :]\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    nll = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(nll.item())\n",
    "    nll.backward()\n",
    "\n",
    "    W.data += -torch.tensor(200.0) * W.grad\n",
    "    W.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5790505409240723\n",
      "2.431211471557617\n",
      "2.401346445083618\n",
      "2.3636972904205322\n",
      "2.3635730743408203\n",
      "2.330418825149536\n",
      "2.337049722671509\n",
      "2.308791399002075\n",
      "2.3189427852630615\n",
      "2.2933919429779053\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    logits = W[x1s, x2s, :]\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    nll = -probs[torch.arange(num), ys].log().mean()\n",
    "    if i%10 == 0:\n",
    "        print(nll.item())\n",
    "    nll.backward()\n",
    "\n",
    "    W.data += -torch.tensor(150.0) * W.grad\n",
    "    W.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2422726154327393\n",
      "2.2320902347564697\n",
      "2.2253077030181885\n",
      "2.2203996181488037\n",
      "2.2166666984558105\n",
      "2.2137210369110107\n",
      "2.2113301753997803\n",
      "2.209345579147339\n",
      "2.2076680660247803\n",
      "2.206228733062744\n",
      "2.2049784660339355\n",
      "2.2038803100585938\n",
      "2.2029073238372803\n",
      "2.202038049697876\n",
      "2.2012557983398438\n",
      "2.200547933578491\n",
      "2.199903726577759\n",
      "2.199314594268799\n",
      "2.198773145675659\n",
      "2.1982738971710205\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    logits = W[x1s, x2s, :]\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    nll = -probs[torch.arange(num), ys].log().mean()\n",
    "    if i%100 == 0:\n",
    "        print(nll.item())\n",
    "    nll.backward()\n",
    "\n",
    "    W.data += -torch.tensor(100.0) * W.grad\n",
    "    W.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..mip.\n",
      "..axx.\n",
      "..mereyannyaar.\n",
      "..knooraen.\n",
      "..el.\n",
      "..marviovania.\n",
      "..odarimalaalexiaganilley.\n",
      "..helahroni.\n",
      "..haat.\n",
      "..affiya.\n",
      "..isemarrisleemikh.\n",
      "..bech.\n",
      "..amilleia.\n",
      "..trutandenneppalycethon.\n",
      "..jan.\n",
      "..kryn.\n",
      "..yusehanii.\n",
      "..laymira.\n",
      "..kni.\n",
      "..steferrysioratten.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the neural net model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    out = []\n",
    "    name = \"..\"\n",
    "    while True:\n",
    "        ix1 = s_to_i[name[-2]]\n",
    "        ix2 = s_to_i[name[-1]]\n",
    "\n",
    "        logits = W[ix1,ix2,:]\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum()\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        name += i_to_s[int(ix)]\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_threshold = int(len(names)*0.8)\n",
    "val_threshold = int(len(names)*0.9)\n",
    "\n",
    "train_names = names[:train_threshold]\n",
    "val_names = names[train_threshold:val_threshold]\n",
    "test_names = names[val_threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alioune',\n",
       " 'alix',\n",
       " 'alois',\n",
       " 'alva',\n",
       " 'amirr',\n",
       " 'amrom',\n",
       " 'aniket',\n",
       " 'ansen',\n",
       " 'apolo',\n",
       " 'aqib']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[train_threshold-5:train_threshold+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('amirr', 'amrom')"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names[-1], val_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_names) + len(val_names) + len(test_names) == len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(182778.) torch.Size([703, 27])\n"
     ]
    }
   ],
   "source": [
    "N = torch.zeros((len(ss_to_i), len(s_to_i)))\n",
    "\n",
    "for name in train_names:\n",
    "    name = '..' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        row = ss_to_i[i+j]\n",
    "        col = s_to_i[k]\n",
    "        N[row, col] += 1\n",
    "print(N.sum(), N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..mir\n",
      "..axx\n",
      "..merfynney\n",
      "..grahamir\n",
      "..ivaj\n",
      "..angerhyx\n",
      "..ron\n",
      "..na\n",
      "..ollah\n",
      "..daishaleilliencelbelyn\n",
      "..race\n",
      "..ta\n",
      "..ceevlah\n",
      "..heigh\n",
      "..roldjqjr\n",
      "..ai\n",
      "..ed\n",
      "..jilleia\n",
      "..trutcjlgmusqxdfzdevbwqplen\n",
      "..kryn\n"
     ]
    }
   ],
   "source": [
    "# Smoothing\n",
    "N = N+1\n",
    "\n",
    "# Use this model to generate some names:\n",
    "\n",
    "P = N / N.sum(1, keepdim=True)\n",
    "\n",
    "assert P[0].sum().item() == 1.0\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = \"..\"\n",
    "    while True:\n",
    "        ss = name[-2:]\n",
    "        i = ss_to_i[ss]\n",
    "        sampled_i = int(torch.multinomial(P[i], 1, replacement=True, generator=g).item())\n",
    "        sampled_s = i_to_s[sampled_i]\n",
    "        if sampled_i == 0:\n",
    "            break\n",
    "        name += sampled_s\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll.item()=2.053244113922119\n"
     ]
    }
   ],
   "source": [
    "# What's the negative loss likelihood of our model on train_names?\n",
    "sumlogprob = torch.tensor(0.0)\n",
    "count = 0\n",
    "for name in train_names:\n",
    "    name = '.' + name + '.'\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        prob = P[ss_to_i[ch1+ch2], s_to_i[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        sumlogprob += logprob\n",
    "        count += 1\n",
    "nll = -sumlogprob / count\n",
    "print(f'{nll.item()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll.item()=2.3264338970184326\n"
     ]
    }
   ],
   "source": [
    "# What's the negative loss likelihood of our model on val_names?\n",
    "sumlogprob = torch.tensor(0.0)\n",
    "count = 0\n",
    "for name in val_names:\n",
    "    name = '.' + name + '.'\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        prob = P[ss_to_i[ch1+ch2], s_to_i[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        sumlogprob += logprob\n",
    "        count += 1\n",
    "nll = -sumlogprob / count\n",
    "print(f'{nll.item()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll.item()=2.337472677230835\n"
     ]
    }
   ],
   "source": [
    "# What's the negative loss likelihood of our model on test_names?\n",
    "sumlogprob = torch.tensor(0.0)\n",
    "count = 0\n",
    "for name in test_names:\n",
    "    name = '.' + name + '.'\n",
    "    for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "        prob = P[ss_to_i[ch1+ch2], s_to_i[ch3]]\n",
    "        logprob = torch.log(prob)\n",
    "        sumlogprob += logprob\n",
    "        count += 1\n",
    "nll = -sumlogprob / count\n",
    "print(f'{nll.item()=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(182778.) torch.Size([703, 27])\n"
     ]
    }
   ],
   "source": [
    "N = torch.zeros((len(ss_to_i), len(s_to_i)))\n",
    "\n",
    "for name in train_names:\n",
    "    name = '..' + name + '.'\n",
    "    for i,j,k in (zip(name, name[1:], name[2:])):\n",
    "        row = ss_to_i[i+j]\n",
    "        col = s_to_i[k]\n",
    "        N[row, col] += 1\n",
    "print(N.sum(), N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0.0\n",
      "nll.item()=nan\n",
      "n=0.05\n",
      "nll.item()=2.3361752033233643\n",
      "n=0.1\n",
      "nll.item()=2.3272202014923096\n",
      "n=0.15000000000000002\n",
      "nll.item()=2.3231360912323\n",
      "n=0.2\n",
      "nll.item()=2.320887565612793\n",
      "n=0.25\n",
      "nll.item()=2.319657802581787\n",
      "n=0.30000000000000004\n",
      "nll.item()=2.319011926651001\n",
      "n=0.35000000000000003\n",
      "nll.item()=2.3187434673309326\n",
      "n=0.4\n",
      "nll.item()=2.31874942779541\n",
      "n=0.45\n",
      "nll.item()=2.318986415863037\n",
      "n=0.5\n",
      "nll.item()=2.3193023204803467\n",
      "n=0.55\n",
      "nll.item()=2.3197741508483887\n",
      "n=0.6000000000000001\n",
      "nll.item()=2.320326089859009\n",
      "n=0.65\n",
      "nll.item()=2.3209550380706787\n",
      "n=0.7000000000000001\n",
      "nll.item()=2.321634531021118\n",
      "n=0.75\n",
      "nll.item()=2.322371482849121\n",
      "n=0.8\n",
      "nll.item()=2.323124408721924\n",
      "n=0.8500000000000001\n",
      "nll.item()=2.3239188194274902\n",
      "n=0.9\n",
      "nll.item()=2.324730157852173\n",
      "n=0.9500000000000001\n",
      "nll.item()=2.3255748748779297\n",
      "n=1.0\n",
      "nll.item()=2.3264338970184326\n"
     ]
    }
   ],
   "source": [
    "for n in np.linspace(0,1,20+1):\n",
    "\n",
    "    print(f'{n=}')\n",
    "    \n",
    "    # Smoothing\n",
    "    NN = N+n\n",
    "\n",
    "    PP = NN / NN.sum(1, keepdim=True)\n",
    "\n",
    "    sumlogprob = torch.tensor(0.0)\n",
    "    count = 0\n",
    "    for name in val_names:\n",
    "        name = '.' + name + '.'\n",
    "        for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
    "            prob = PP[ss_to_i[ch1+ch2], s_to_i[ch3]]\n",
    "            logprob = torch.log(prob)\n",
    "            sumlogprob += logprob\n",
    "            count += 1\n",
    "    nll = -sumlogprob / count\n",
    "    print(f'{nll.item()=}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..mir\n",
      "..axx\n",
      "..mereyannya\n",
      "..salonaia\n",
      "..raad\n",
      "..marwinzephhara\n",
      "..ollah\n",
      "..daishaleilliencelbelyn\n",
      "..race\n",
      "..ta\n",
      "..ceevi\n",
      "..iselannamie\n",
      "..mell\n",
      "..ai\n",
      "..ed\n",
      "..jilleia\n",
      "..trutchelissitaey\n",
      "..crevilean\n",
      "..kryn\n",
      "..yuridanjine\n"
     ]
    }
   ],
   "source": [
    "# Smoothing\n",
    "NN = N+0.375\n",
    "\n",
    "# Use this model to generate some names:\n",
    "\n",
    "P = NN / NN.sum(1, keepdim=True)\n",
    "\n",
    "assert P[1].sum().item() - 1.0 < 1e-5\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "    name = \"..\"\n",
    "    while True:\n",
    "        ss = name[-2:]\n",
    "        i = ss_to_i[ss]\n",
    "        sampled_i = int(torch.multinomial(P[i], 1, replacement=True, generator=g).item())\n",
    "        sampled_s = i_to_s[sampled_i]\n",
    "        if sampled_i == 0:\n",
    "            break\n",
    "        name += sampled_s\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=10.0\n",
      "nll=tensor(2.8295, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.8946, grad_fn=<AddBackward0>)\n",
      "r=1.0\n",
      "nll=tensor(2.3131, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.4403, grad_fn=<AddBackward0>)\n",
      "r=0.1\n",
      "nll=tensor(2.0189, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.1990, grad_fn=<AddBackward0>)\n",
      "r=0.01\n",
      "nll=tensor(1.9246, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.1490, grad_fn=<AddBackward0>)\n",
      "r=0.001\n",
      "nll=tensor(1.9056, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.1413, grad_fn=<AddBackward0>)\n",
      "r=0.0001\n",
      "nll=tensor(1.9034, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.1390, grad_fn=<AddBackward0>)\n",
      "r=1e-05\n",
      "nll=tensor(1.9058, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.1428, grad_fn=<AddBackward0>)\n",
      "r=1e-06\n",
      "nll=tensor(1.9058, grad_fn=<AddBackward0>)\n",
      "nll=tensor(2.1439, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1s_train = x1s[:dev_threshold]\n",
    "x1s_val = x1s[dev_threshold:val_threshold]\n",
    "x1s_test = x1s[val_threshold:]\n",
    "\n",
    "x2s_train = x2s[:dev_threshold]\n",
    "x2s_val = x2s[dev_threshold:val_threshold]\n",
    "x2s_tes = x2s[val_threshold:]\n",
    "\n",
    "ys_train = ys[:dev_threshold]\n",
    "ys_val = ys[dev_threshold:val_threshold]\n",
    "ys_test = ys[val_threshold:]\n",
    "\n",
    "\n",
    "\n",
    "for r in [1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "\n",
    "    W = torch.rand((27,27,27), dtype=torch.float, requires_grad=True)\n",
    "    num = x1s_train.nelement()\n",
    "\n",
    "    for i in range(20):\n",
    "        logits = W[x1s_train, x2s_train, :]\n",
    "        counts = torch.exp(logits)\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "        nll = -probs[torch.arange(num), ys_train].log().mean() + r * (W*W).mean()\n",
    "        nll.backward()\n",
    "\n",
    "        W.data += -torch.tensor(200.0) * W.grad\n",
    "        W.grad = None\n",
    "\n",
    "    for i in range(100):\n",
    "        logits = W[x1s_train, x2s_train, :]\n",
    "        counts = torch.exp(logits)\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "        nll = -probs[torch.arange(num), ys_train].log().mean() + r * (W*W).mean()\n",
    "        nll.backward()\n",
    "\n",
    "        W.data += -torch.tensor(150.0) * W.grad\n",
    "        W.grad = None\n",
    "\n",
    "    for i in range(2000):\n",
    "        logits = W[x1s_train, x2s_train, :]\n",
    "        counts = torch.exp(logits)\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "        nll = -probs[torch.arange(num), ys_train].log().mean() + r * (W*W).mean()\n",
    "        nll.backward()\n",
    "\n",
    "        W.data += -torch.tensor(100.0) * W.grad \n",
    "        W.grad = None\n",
    "    \n",
    "    print(f'{r=}')\n",
    "    print(f'{nll=}')\n",
    "    \n",
    "    \n",
    "    num = x1s_val.nelement()\n",
    "    logits = W[x1s_val, x2s_val, :]\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    nll = -probs[torch.arange(num), ys_val].log().mean() + r * (W*W).mean()\n",
    "    \n",
    "    print(f'{nll=}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we did that already above. Instead of using the one-hot vector we can just index into the matrix/tensor, since I couldn't make the one-hot vector approach work for the 3D tensor model\n",
    "\n",
    "We did this above when doing:\n",
    "\n",
    "```\n",
    "logits = W[x1s, x2s, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.tensor(np.arange(16))\n",
    "W = W.reshape([4,4])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc = torch.nn.functional.one_hot(torch.tensor(3), num_classes=4)\n",
    "x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 13, 14, 15])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 13, 14, 15])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (x_enc @ W == W[3]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E05: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, cross entropy is the same as softmax + nll (see also exercises from lesson 1)\n",
    "\n",
    "Cross entropy is probably doing some more optimizations, numerically more stable, less manual work so less probability of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E06: meta-exercise! Think of a fun/interesting exercise and complete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c13b8769d29b9cf5cf47e8da9da13ab52310a6e33afb9474b0da20ac390dd33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
